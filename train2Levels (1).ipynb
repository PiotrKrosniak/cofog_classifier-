{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e680dea-9eb5-4990-a0af-4174dc426212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('balanced2.csv')\n",
    "\n",
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# You can define your train-test split here if needed\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c47caa0-c86f-43cd-bb03-813f4dcbe9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f914c4e4a50940029c6a02c9691f7e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0ec2fc9f824e58a719dc03a1c414d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['line'], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4b6c86-899f-4e40-891e-5441f6b1f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Creating label encoders for level1 and level2\n",
    "label_encoder_level1 = LabelEncoder()\n",
    "label_encoder_level2 = LabelEncoder()\n",
    "\n",
    "# Encoding level1 and level2 labels\n",
    "df['encoded_level1'] = label_encoder_level1.fit_transform(df['level1'])\n",
    "df['encoded_level2'] = label_encoder_level2.fit_transform(df['level2'])\n",
    "\n",
    "# Save the label encoders for later use\n",
    "with open('label_encoder_level1.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder_level1, file)\n",
    "\n",
    "with open('label_encoder_level2.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder_level2, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993b0299-d25b-48dd-99b8-b7ce25b3fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data frames for level1 and level2 label classes\n",
    "label_classes_level1 = label_encoder_level1.classes_\n",
    "df_label_classes_level1 = pd.DataFrame(label_classes_level1, columns=[\"Level1 Label Names\"])\n",
    "df_label_classes_level1.index.name = \"Encoded Level1 Label\"\n",
    "df_label_classes_level1.reset_index(inplace=True)\n",
    "\n",
    "label_classes_level2 = label_encoder_level2.classes_\n",
    "df_label_classes_level2 = pd.DataFrame(label_classes_level2, columns=[\"Level2 Label Names\"])\n",
    "df_label_classes_level2.index.name = \"Encoded Level2 Label\"\n",
    "df_label_classes_level2.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de585ad0-dba5-43dd-a5c1-8f8cb0384a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>encoded_level1</th>\n",
       "      <th>encoded_level2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General Maintenance Works at State House Nairobi</td>\n",
       "      <td>General public services</td>\n",
       "      <td>Executive and legislative organs, financial an...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>General Maintenance Works at State House Sagana</td>\n",
       "      <td>General public services</td>\n",
       "      <td>Executive and legislative organs, financial an...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Refurbishment of buildings at Mombasa State House</td>\n",
       "      <td>General public services</td>\n",
       "      <td>Executive and legislative organs, financial an...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Refurbishment of buildings at Nakuru State House</td>\n",
       "      <td>General public services</td>\n",
       "      <td>Executive and legislative organs, financial an...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Works at the Office of the Deputy Pres...</td>\n",
       "      <td>General public services</td>\n",
       "      <td>Executive and legislative organs, financial an...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                line                   level1  \\\n",
       "0   General Maintenance Works at State House Nairobi  General public services   \n",
       "1    General Maintenance Works at State House Sagana  General public services   \n",
       "2  Refurbishment of buildings at Mombasa State House  General public services   \n",
       "3   Refurbishment of buildings at Nakuru State House  General public services   \n",
       "4  General Works at the Office of the Deputy Pres...  General public services   \n",
       "\n",
       "                                              level2  encoded_level1  \\\n",
       "0  Executive and legislative organs, financial an...               4   \n",
       "1  Executive and legislative organs, financial an...               4   \n",
       "2  Executive and legislative organs, financial an...               4   \n",
       "3  Executive and legislative organs, financial an...               4   \n",
       "4  Executive and legislative organs, financial an...               4   \n",
       "\n",
       "   encoded_level2  \n",
       "0               8  \n",
       "1               8  \n",
       "2               8  \n",
       "3               8  \n",
       "4               8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "773d00ed-5d73-4cc4-907c-05c12fc39382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd71b3c-f274-44be-8097-67f7e47df1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e63f1ca6f654a35ab104a0510794ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06b9278a8c242c49b42211cc634a76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b14a055875472eb0106574cbf66d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f58bfb8f4947f59bdd901c382513aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410a4e2b3bb041e2b1d0c134003575ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5f4bc06fbf4ed5b7fcded094c1a3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure the 'encoded_level1' column is included in the datasets\n",
    "train_dataset = train_dataset.map(lambda e: {'encoded_level1': e['encoded_level1']})\n",
    "eval_dataset = eval_dataset.map(lambda e: {'encoded_level1': e['encoded_level1']})\n",
    "\n",
    "# Tokenization\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Add the 'encoded_level1' as labels in the tokenized dataset\n",
    "tokenized_train_dataset = tokenized_train_dataset.map(lambda e: {'labels': e['encoded_level1']})\n",
    "tokenized_eval_dataset = tokenized_eval_dataset.map(lambda e: {'labels': e['encoded_level1']})\n",
    "\n",
    "# Set the format for PyTorch\n",
    "tokenized_train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849adaeb-492f-4dd4-b7f9-899cdf351847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc}\n",
    "def compute_metrics_level2(pred):\n",
    "    labels_level2 = pred.label_ids  # These are the true level2 labels\n",
    "    preds_level2 = pred.predictions.argmax(-1)  # These are the predicted level2 labels\n",
    "    acc_level2 = accuracy_score(labels_level2, preds_level2)\n",
    "    return {'accuracy_level2': acc_level2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573dd078-53b5-4456-8cf1-c0e5cbfc30fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 16:06:23.422324: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='395' max='395' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [395/395 1:31:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.082498</td>\n",
       "      <td>0.398089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.432583</td>\n",
       "      <td>0.684713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.779877</td>\n",
       "      <td>0.815287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.481315</td>\n",
       "      <td>0.869427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.437809</td>\n",
       "      <td>0.894904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=395, training_loss=1.1993534909018988, metrics={'train_runtime': 5536.4638, 'train_samples_per_second': 1.134, 'train_steps_per_second': 0.071, 'total_flos': 1652456113029120.0, 'train_loss': 1.1993534909018988, 'epoch': 5.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Update num_labels to reflect the number of unique labels in level1\n",
    "num_labels_level1 = len(label_encoder_level1.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels_level1)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,  # Adjust as needed\n",
    "    per_device_train_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",  # Evaluation strategy\n",
    "    save_strategy=\"epoch\",  # Make save strategy match the evaluation strategy\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    compute_metrics=compute_metrics,  # Use the compute_metrics function for level1\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1ffd25f-993b-4050-a230-a2aabee74cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1740e7be2e2c49c5b83441ef7ad28d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90601b67ab42455f9a691e6b06fbca71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc951e54144c4009a2629631d946173e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa48e3c1a0a4c89aba7e9bf9d4e6964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90b2c333d514b50b5e2ca0c7e0b2ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb73ef967464eee914e0f8acc49a1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure the 'encoded_level1' column is included in the datasets\n",
    "train_dataset2 = train_dataset.map(lambda e: {'encoded_level2': e['encoded_level2']})\n",
    "eval_dataset2 = eval_dataset.map(lambda e: {'encoded_level2': e['encoded_level2']})\n",
    "\n",
    "# Tokenization\n",
    "tokenized_train_dataset2 = train_dataset2.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset2 = eval_dataset2.map(tokenize_function, batched=True)\n",
    "\n",
    "# Add the 'encoded_level1' as labels in the tokenized dataset\n",
    "tokenized_train_dataset2 = tokenized_train_dataset2.map(lambda e: {'labels': e['encoded_level2']})\n",
    "tokenized_eval_dataset2 = tokenized_eval_dataset2.map(lambda e: {'labels': e['encoded_level2']})\n",
    "\n",
    "# Set the format for PyTorch\n",
    "tokenized_train_dataset2.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_eval_dataset2.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a015ee3-045e-4f13-9fdf-6ef6d7dd4fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='283' max='395' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [283/395 1:07:59 < 27:06, 0.07 it/s, Epoch 3.57/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Level2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.965576</td>\n",
       "      <td>0.031847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.698133</td>\n",
       "      <td>0.136943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.179410</td>\n",
       "      <td>0.257962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Assuming you have already predicted level1 labels and prepared the data for level2\n",
    "# Update num_labels to reflect the number of unique labels in level2\n",
    "num_labels_level2 = len(label_encoder_level2.classes_)\n",
    "model_level2 = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels_level2)\n",
    "\n",
    "# You may use similar training arguments, but ensure to differentiate the output directory\n",
    "training_args_level2 = TrainingArguments(\n",
    "    output_dir='./results_level2',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs_level2',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy_level2',\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Tokenize your modified dataset for level2 and then create a Trainer instance\n",
    "# Assuming tokenized_train_dataset_level2 and tokenized_eval_dataset_level2 are ready\n",
    "trainer_level2 = Trainer(\n",
    "    model=model_level2,\n",
    "    args=training_args_level2,\n",
    "    train_dataset=tokenized_train_dataset2,\n",
    "    eval_dataset=tokenized_eval_dataset2,\n",
    "    compute_metrics=compute_metrics_level2,  # Adjust compute_metrics if needed for level2\n",
    ")\n",
    "\n",
    "trainer_level2.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab1097-10ca-4cab-9348-edf6a4e647ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
